<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Parallel Computation with R</title>

		<meta name="description" content="">
		<meta name="author" content="Isabelle Beaudry, Evan L. Ray">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/sky.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/mono-blue.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->

		<link rel="stylesheet" href="css/fullheight.css">
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h2 style = "margin-top:5cm">Parallel Computation with R</h2>
					
					<p>
						Isabelle Beaudry, 
						Evan L. Ray
					</p>
					<p>
						University of Massachusetts, Amherst
					</p>
					<p>
						April 14, 2014
					</p>
				</section>

				<section>
					<h3>Outline</h3>
					<ol>
						<li>Some context: options when your code is slow</li>
						<li>A running example: network simulation</li>
						<li>Parallel computing on one computer, multiple cores
							<ul>
								<li>Overview</li>
								<li>snowfall (+ rstream)</li>
								<li>foreach with doParallel and doRNG</li>
							</ul>
						</li>
						<li>Parallel computing on a cluster: the MGHPCC
							<ul>
								<li>Overview</li>
								<li>Logistics: connecting, transferring files, and submitting jobs</li>
							</ul>
						</li>
					</ol>
				</section>

				<section>
					<h3>So your code runs slowly...</h3>
					<span style="position:absolute; top:100px; left:450px;" class="fragment fade-out"> <img height="550px;" src="images/turtle-running.gif" /> </span>
					<ul class="fragment">
						<li> <span style="font-weight:bold;"> Step 0: </span> Make sure you're getting the right answer.
							<ul>
								<li> <q> &ldquo;We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.&rdquo; - Donald Knuth </q> </li>
								<li> Consider unit testing:  See packages Runit and testthat </li>
							</ul>
						</li>
						<li> <span style="font-weight:bold"> Step 1: </span> Profile your code to see where it's slow
							<ul>
								<li> See Rprof and the package profr </li>
							</ul>
						</li>
						<li> <span style="font-weight:bold"> Step 2: </span> Consider using a different algorithm. </li>
						<li> <span style="font-weight:bold"> Step 3: </span> Consider modifying your R code
							<ul>
								<li> Pre-allocate memory </li>
								<li> Use built-in functions instead of loops </li>
							</ul>
						</li>
						<li> <span style="font-weight:bold"> Step 4 (a): </span> Consider parallelizing </li>
						<li> <span style="font-weight:bold"> Step 4 (b): </span> Consider using a faster language for the slow parts.
							<ul>
								<li> See package Rcpp </li>
							</ul>
						</li>
					</ul>
				</section>


<!--				<section>
					<h3>Parallel Execution</h3>
					<ul>
						<li>Computations are done simultaneously.</li>
						<li>Embarassingly Parallel: the tasks being done in parallel don't need to communicate with each other: e.g.,
							<ul>
								<li> Simulation studies </li>
								<li> Boostrapping </li>
								<li> Random forests </li>
							</ul>
						</li>
					</ul>
				</section>
-->

				<section>
					<h3>Some General Resources</h3>
					<ul>
						<li> Advanced R development, by Hadley Wickham
							<ul>
								<li> <a href="http://adv-r.had.co.nz/">http://adv-r.had.co.nz/</a> </li>
							</ul>
						</li>
						<li> 2008 UseR presentation by Dirk Eddelbuettel: 
							<ul>
								<li> <a href="http://www.statistik.uni-dortmund.de/useR-2008/tutorials/useR2008introhighperfR.pdf">http://www.statistik.uni-dortmund.de/useR-2008/tutorials/useR2008introhighperfR.pdf</a> </li>
							</ul>
						</li>
						<li> High performance computing task view on CRAN:
							<ul>
								<li> <a href="http://cran.r-project.org/web/views/HighPerformanceComputing.html">http://cran.r-project.org/web/views/HighPerformanceComputing.html</a> </li>
							</ul>
						</li>
					</ul>
				</section>


				<section>
					<h3>Example: network simulations</h3>
					<ul>
						<li> We want to conduct a simulation study to evaluate a method for estimating a population proportion from a respondent-driven sample (RDS).
						</li>
						<li> Each step of the simulation will require the following:
							<ol>
								<li> Simulate a network at random
								</li>
								<li> Draw a sample from this network according to the RDS design
								</li>
								<li> Estimate the population proportion
								</li>
							</ol>
						</li>
					</ul>
<img style="position:absolute; top:300px; left:170px;"  height="300px;" src="images/net.png" /><img style="position:absolute; top:300px; left:650px;" height="300px;" src="images/sample.png" />
				</section>


				<section>
					<h3>Example: network simulations</h3>
					<ul>
						<li> Here's some code to do this simulation study: </li>
					</ul>
					<pre style="width:1300px; background-color:#ffffff;"><code># ...load packages, define necessary functions, etc...

# allocate memory to store results
rds.sample1 <- array(NA, dim=c(n.net, n.nodes, 5))
est <- rep(NA, n.net)

for (j in 1:n.net){
  # simulate one network
  net <- create.nets(1)

  # simulate a respondent driven sample from the network
  rds.sample1[j, , ] <- rds.s(net)
  rds.frame <- create.df(A, rds.sample1[j, , ], rds.sample1[j, , 2])

  # estimate a population proportion based on the respondent driven sample
  est[j] <- RDS.II.estimates(rds.frame, outcome.variable="outcome")$estimate
}</code></pre>
				</section>

				<section>
					<h3>Parallelization with Snowfall</h3>
					<ul>
						<li> We can parallelize this simulation using the snowfall package as follows:</li>
					</ul>
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">library(snowfall)

# ...load packages, define necessary functions, etc...

# create a cluster with 4 cpus, using sockets for communication
sfInit(parallel = TRUE, cpus = 4, type = "SOCK")

# export all objects in the global environment to the cluster nodes.
# see also the sfExport function for exporting specific objects.
sfExportAll()

# load libraries on the cluster nodes
sfLibrary("statnet", character.only = TRUE)
sfLibrary("RDS", character.only = TRUE)

# replace the for loop with sfSapply: snowfall's equivalent of sapply
est <- sfSapply(seq_len(n.net), function(j) {
  net <- create.nets(1)
  rds.sample <- rds.s(net)
  rds.frame <- create.df(A, rds.sample, rds.sample[, 2])
  return(RDS.II.estimates(rds.frame, outcome.variable = "outcome")$estimate)
}

# stop the cluster
sfStop()</code></pre>
				</section>


				<section>
					<h3>Be careful about random numbers!!</h3>
					<ul>
						<li> You must take care to ensure that:
							<ul>
								<li> results are reproducible
								</li>
								<li> numbers generated are independent
								</li>
							<ul>
						</li>
					</ul>
					<span style="position:absolute; top:70px; left:300px;" class="fragment fade-out"> <img height="550px;" src="images/caution.png" /> </span>
				</section>


				<section>
					<h3>Revised Example: Using the rstream package</h3>
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">library(snowfall)
library(rstream)
sfInit(parallel = TRUE, cpus = 4, type = "SOCK")

# create an rstream object.  It requires 6 integers as a seed.
set.seed(1)
rngstream <- new("rstream.mrg32k3a", seed=sample(1:10000, 6, replace = FALSE))

# pack the rng stream in preparation for exporting to cluster nodes
rstream.packed(rngstream) <- TRUE

sfExportAll()

sfLibrary("rstream", character.only = TRUE)
sfLibrary("statnet", character.only = TRUE)
sfLibrary("RDS", character.only = TRUE)

est <- sfSapply(seq_len(n.net), function(j) {
  # unpack the rng stream
  rstream.packed(rngstream) <- FALSE

  # advance to a substream specific to this iteration of the simulation
  for(i in seq_len(j))
    rstream.nextsubstream(rngstream)
  
  # set the rng stream so that it is used by R in random number generation
  rstream.RNG(rngstream)

  net <- create.nets(1)
  rds.sample <- rds.s(net)
  rds.frame <- create.df(A, rds.sample, rds.sample[, 2])
  return(RDS.II.estimates(rds.frame, outcome.variable = "outcome")$estimate)
})

sfStop()</code></pre>
				</section>

				<section>
					<h3>The foreach Package with doRNG</h3>
					<ul>
						<li> The foreach package provides the following general construction:
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">foreach(i = 1:3) %dopar% {
  # do some stuff
}</code></pre>
						</li>
						<li> We have to register a parallel backend with foreach.</li>
<div class="fragment">
						<li> There are many options: doParallel/parallel, doMPI/Rmpi, doMC/multicore, doSNOW/snow </li>
						<li> We will use the package doRNG for random number generation:
							<ul>
								<li> Ties into doParallel or doMPI to handle parallelization
								</li>
								<li> Enables reproducible RNG
								</li>
							</ul>
						</li>
</div>
					</ul>
				</section>


				<section>
					<h3>Implementing our Example with doRNG</h3>
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">library(doParallel)
library(doRNG)

# create a cluster with 4 cpus
nCores <- 4
cl <- makeCluster(nCores)

# register the cluster so that doParallel is used as the back end
registerDoParallel(cl)

# export all objects to the cluster nodes
clusterExport(cl = cl, ls(), envir = environment())

# parallelize the for loop using foreach and doRNG
# load the packages statnet and RDS on the cluster nodes
# set the RNG seed to 123
# combine results using the cbind function
est <- foreach(i = 1:n.net, .packages = c("statnet", "RDS"),
        .options.RNG = 123, .combine = cbind) %dorng% {
  net <- create.nets(1)
  rds.sample3 <- rds.s(net)
  rds.frame <- create.df(A, rds.sample3, rds.sample3[, 2])
  return(RDS.II.estimates(rds.frame, outcome.variable = "outcome")$estimate)
}

# stop the cluster
stopCluster(cl)</code></pre>
				</section>


				<section>
					<h3>MGHPCC</h3>
					<img height="250px;" src="images/mghpcc.jpg" />
					<ul>
						<li> The Massachusetts Green High Performance Computing Center is:
							<ul>
								<li> Run by University of Massachusetts, Boston University, Harvard University, MIT, and Northeastern University </li>
								<li> 5312 cores available and 400TBs of storage </li>
								<li> LEED Platinum certified </li>
								<li> located in Holyoke </li>
							</ul>
						</li>
						<li> There is a wiki at <a href="http://wiki.umassrc.org/wiki">http://wiki.umassrc.org/wiki</a></li>
						<li> You can request access at <a href="http://wiki.umassrc.org/wiki/index.php/Requesting_Access">http://wiki.umassrc.org/wiki/index.php/Requesting_Access</a></li>
					</ul>
				</section>

				<section>
					<h3>Logistics: Connecting, Transferring Files, and Submitting Jobs</h3>
					<ul>
						<li> To use the cluster, we need to do the following:
							<ol>
								<li> Transfer data/scripts to the cluster with FTP </li>
								<li> Log in to the cluster </li>
								<li> Install any needed packages </li>
								<li> Submit a job </li>
								<li> Transfer data/results back from the cluster to your computer </li>
							</ol>
						</li>
						<li> Detailed instructions for transferring files and logging in are on the BiP slides, link on last page
							<ul>
								<li>But there is an important step missing for Windows users!!!
									<p> After uploading your scripts, run dos2unix to convert file formats. For example,</p>
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">dos2unix network_sf_rstream.R</code></pre>
								</li>
							</ul>
						</li>
						<li> Next, we will discuss installing packages and submitting jobs </li>
					</ul>
				</section>


				<section>
					<h3>Installing Packages</h3>
					<ul>
						<li> The cluster does not have many R packages installed by default.  To install them, you need to:
							<ol>
								<li> Load necessary modules (software packages):
									<ul>
										<li> You will need the R module:
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">module load R/3.0.2</code></pre>
										</li>
										<li> For some packages, you may need to load other modules such as the C/C++ compiler gcc:
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">module load gcc/4.8.1</code></pre>
										</li>
										<li> You can view the full list of available modules with the following command (or on the wiki):
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">module avail</code></pre>
										</li>
									</ul>
								</li>
								<li> Install the package as usual, using install.packages() from within R or R CMD INSTALL from the command line.
								</li>
							</ol>
					</ul>
				</section>


				<section>
					<h3>Submitting Jobs</h3>
					<ul>
						<li> Once you have uploaded your scripts to the cluster, there are two steps to run them:
							<ol>
								<li> Create a shell script like the following:
<pre style="width:1300px; background-color:#ffffff;" class="R"><code class="R">#!/bin/bash
#BSUB -R rusage[mem=1024] # ask for memory
#BSUB -n 4                # how many cores we want for our job
#BSUB -R span[hosts=1]    # ask for all the cores on a single machine
#BSUB -W 0:10             # not sure what this is doing
#BSUB -q short            # which queue we want to run in

module load R/3.0.2
R CMD BATCH /home/er71a/ParallelR/network_sf_rstream.R</code></pre>
								</li>
								<li> Submit to the scheduler
								</li>
							</ol>
					</ul>
<img src="images/submitss.png" />
				</section>

				<section>
					<h3>Results</h3>
					<span><img src="images/giveamouse.jpg" style = "width:400px; position:absolute; top:70px; left:-20px;" /></span>
					<ul style = "width:600px; margin-left: 280px;">
						<li> If you give a mouse access to a cluster, he'll want to run a job on it. </li>
						<li> After he runs his job, he'll want to look at the results. </li>
						<div class="fragment">
						<li> After your job runs, the console log will be in a file like network_sf_rstream.Rout. </li>
						<li> If you will need access to other R objects, you will need to explicitly save them!
							<ul>
								<li> For saving plots: png(), jpeg(), pdf() </li>
								<li> For saving objects: save(), save.image() </li>
							</ul>
						</li>
						<li> You may want to save intermediate results. </li>
						</div>
					</ul>
				</section>

				<section>
					<h3>Resources</h3>
					<ul>
						<li> These slides and our example code are available on GitHub:
							<ul>
								<li><a href = "https://github.com/elray1/ParallelR">https://github.com/elray1/ParallelR</a></li>
								<li> The HTML slides probably only display correctly with google chrome; there is also a pdf version. </li>
							</ul>
						</li> 
						<li> The Biostatistics in Practice slides and examples are also available on GitHub:
							<ul>
								<li><a href = "https://github.com/nickreich/BiPSandbox/">https://github.com/nickreich/BiPSandbox/</a></li>
								<li> Module 2 talks about parallel computation on a local machine </li>
								<li> Module 3 talks about parallel computation on the MGHPCC</li>
							</ul>
						</li>
					</ul>
				</section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none

				width: 1280,
//				height: 100%,
				margin: 0.01,

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
